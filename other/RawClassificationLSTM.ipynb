{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "from keras import utils, models, layers, backend, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAF_DOSE = 200\n",
    "STAGE = 'NREM'\n",
    "TEST_SUBJECT_COUNT = 3\n",
    "\n",
    "DATA_PATH = 'C:\\\\Users\\\\Philipp\\\\Documents\\\\Caffeine\\\\raw_eeg{dose}'.format(dose=CAF_DOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawGenerator(utils.Sequence):\n",
    "    \n",
    "    def __init__(self, files_caf, files_plac, files_per_batch):\n",
    "        self.files_caf, self.files_plac = np.array(files_caf), np.array(files_plac)\n",
    "        self.files_per_batch = files_per_batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(min(len(self.files_caf), len(self.files_plac)) / self.files_per_batch))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.files_per_batch\n",
    "        end = (idx + 1) * self.files_per_batch\n",
    "        \n",
    "        batch_files_caf = self.files_caf[start:end]\n",
    "        batch_files_plac = self.files_plac[start:end]\n",
    "        \n",
    "        batch_data_list_caf = [np.load(file) for file in batch_files_caf]\n",
    "        samples_per_file_caf = [x.shape[0] for x in batch_data_list_caf]\n",
    "        \n",
    "        batch_data_list_plac = [np.load(file) for file in batch_files_plac]\n",
    "        samples_per_file_plac = [x.shape[0] for x in batch_data_list_plac]\n",
    "        \n",
    "        batch_x = np.concatenate(batch_data_list_caf + batch_data_list_plac, axis=0)\n",
    "        batch_y = np.array([[1, 0]] * np.sum(samples_per_file_caf) + [[0, 1]] * np.sum(samples_per_file_plac))\n",
    "        \n",
    "        batch_x = utils.normalize(batch_x, axis=0)\n",
    "        \n",
    "        perm = np.random.permutation(batch_x.shape[0])\n",
    "        return batch_x[perm], batch_y[perm]\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.files_caf = self.files_caf[np.random.permutation(len(self.files_caf))]\n",
    "        self.files_plac = self.files_plac[np.random.permutation(len(self.files_plac))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_subject_id(path):\n",
    "    return re.match('\\S\\d+', path.split(os.sep)[-1].split('_')[0])[0]\n",
    "    \n",
    "caf_files = glob.glob(os.path.join(DATA_PATH, f'*{STAGE}*CAF*'))\n",
    "plac_files = glob.glob(os.path.join(DATA_PATH, f'*{STAGE}*PLAC*'))\n",
    "\n",
    "caf_subjects = set([get_subject_id(file) for file in caf_files])\n",
    "plac_subjects = set([get_subject_id(file) for file in plac_files])\n",
    "\n",
    "subjects = caf_subjects & plac_subjects\n",
    "\n",
    "test_subjects = set()\n",
    "while len(test_subjects) < TEST_SUBJECT_COUNT:\n",
    "    test_subjects.add(np.random.choice(list(subjects)))\n",
    "    \n",
    "caf_files_train = [file for file in caf_files if get_subject_id(file) not in test_subjects]\n",
    "plac_files_train = [file for file in plac_files if get_subject_id(file) not in test_subjects]\n",
    "caf_files_test = [file for file in caf_files if get_subject_id(file) in test_subjects]\n",
    "plac_files_test = [file for file in plac_files if get_subject_id(file) in test_subjects]\n",
    "\n",
    "train = RawGenerator(caf_files_train, plac_files_train, 3)\n",
    "test = RawGenerator(caf_files_test, plac_files_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Philipp\\Anaconda3\\envs\\mne\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 32)                6784      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 7,906\n",
      "Trainable params: 7,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "backend.clear_session()\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(units=32, input_shape=(5120, 20)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Philipp\\Anaconda3\\envs\\mne\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 1360s 13s/step - loss: 0.6933 - acc: 0.5032 - val_loss: 0.6930 - val_acc: 0.5054\n",
      "Epoch 2/100\n",
      " 40/108 [==========>...................] - ETA: 20:31 - loss: 0.6930 - acc: 0.5035"
     ]
    }
   ],
   "source": [
    "name = datetime.datetime.now().strftime('lstm_%Y-%m-%d_%H-%M-%S')\n",
    "tensorboard = callbacks.TensorBoard(log_dir='..\\\\results\\\\logs\\\\' + name)\n",
    "\n",
    "model.fit_generator(generator=train,\n",
    "                    epochs=100,\n",
    "                    validation_data=test,\n",
    "                    max_queue_size=6,\n",
    "                    workers=6,\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy:', model.evaluate_generator(train)[1])\n",
    "print('Testing accuracy: ', model.evaluate_generator(test)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
