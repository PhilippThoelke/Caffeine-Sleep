{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras import models, utils\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAF_DOSE = 200\n",
    "STAGE = 'NREM'\n",
    "\n",
    "DATA_PATH = 'C:\\\\Users\\\\Philipp\\\\Documents\\\\Caffeine\\\\raw_eeg{dose}'.format(dose=CAF_DOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawGenerator(utils.Sequence):\n",
    "    \n",
    "    def __init__(self, files_caf, files_plac, files_per_batch, permute_labels=False):\n",
    "        self.files_caf, self.files_plac = np.array(files_caf), np.array(files_plac)\n",
    "        self.files_per_batch = files_per_batch\n",
    "        self.permute_labels = permute_labels\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(min(len(self.files_caf), len(self.files_plac)) / self.files_per_batch))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.files_per_batch\n",
    "        end = (idx + 1) * self.files_per_batch\n",
    "        \n",
    "        batch_files_caf = self.files_caf[start:end]\n",
    "        batch_files_plac = self.files_plac[start:end]\n",
    "        \n",
    "        batch_data_list_caf = [np.load(file) for file in batch_files_caf]\n",
    "        samples_per_file_caf = [x.shape[0] for x in batch_data_list_caf]\n",
    "        \n",
    "        batch_data_list_plac = [np.load(file) for file in batch_files_plac]\n",
    "        samples_per_file_plac = [x.shape[0] for x in batch_data_list_plac]\n",
    "        \n",
    "        batch_x = np.concatenate(batch_data_list_caf + batch_data_list_plac, axis=0)\n",
    "        batch_y = np.array([[0, 1]] * np.sum(samples_per_file_caf) + [[1, 0]] * np.sum(samples_per_file_plac))\n",
    "        \n",
    "        for i in range(batch_x.shape[2]):\n",
    "            preprocessing.normalize(batch_x[:,:,i], norm='l2', axis=1, copy=False)\n",
    "\n",
    "        \n",
    "        if self.permute_labels:\n",
    "            labels = [[1, 0]] * (len(batch_y) // 2) + [[0, 1]] * (len(batch_y) // 2)\n",
    "            if len(labels) < len(batch_y):\n",
    "                labels += [[1, 0]]\n",
    "            batch_y = np.array(labels)\n",
    "            return batch_x[np.random.permutation(batch_x.shape[0])], batch_y[np.random.permutation(batch_y.shape[0])]\n",
    "        else:\n",
    "            perm = np.random.permutation(batch_x.shape[0])\n",
    "            return batch_x[perm], batch_y[perm]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.files_caf = self.files_caf[np.random.permutation(len(self.files_caf))]\n",
    "        self.files_plac = self.files_plac[np.random.permutation(len(self.files_plac))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using raw EEG data from 40 subjects\n"
     ]
    }
   ],
   "source": [
    "def get_subject_id(path):\n",
    "    return re.match('\\S\\d+', path.split(os.sep)[-1].split('_')[0])[0]\n",
    "    \n",
    "caf_files = glob.glob(os.path.join(DATA_PATH, f'*{STAGE}*CAF*'))\n",
    "plac_files = glob.glob(os.path.join(DATA_PATH, f'*{STAGE}*PLAC*'))\n",
    "\n",
    "caf_subjects = set([get_subject_id(file) for file in caf_files])\n",
    "plac_subjects = set([get_subject_id(file) for file in plac_files])\n",
    "\n",
    "used = set(pickle.load(open('..\\\\subjects.pickle', 'rb')))\n",
    "\n",
    "subjects = caf_subjects & plac_subjects\n",
    "\n",
    "print(f'Using raw EEG data from {len(subjects)} subjects')\n",
    "    \n",
    "caf_files = [file for file in caf_files if get_subject_id(file) in subjects]\n",
    "plac_files = [file for file in plac_files if get_subject_id(file) in subjects]\n",
    "\n",
    "data = RawGenerator(caf_files, plac_files, 1, permute_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('..\\\\model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy after batch (437/437): 71.582%\r"
     ]
    }
   ],
   "source": [
    "acc_sum = 0\n",
    "\n",
    "for batch in range(len(data)):\n",
    "    current = data[batch]\n",
    "    acc_sum += model.evaluate(current[0], current[1], verbose=0)[1]\n",
    "    print(f'Mean accuracy after batch ({batch + 1}/{len(data)}): {acc_sum / (batch + 1) * 100:.3f}%', end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
